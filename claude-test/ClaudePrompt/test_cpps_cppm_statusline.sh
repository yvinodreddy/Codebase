#!/bin/bash
#
# test_cpps_cppm_statusline.sh - Verify cpps and cppm work with statusline
#
# Tests that both cpps and cppm commands correctly update ALL statusline metrics:
# - Agents (cumulative count)
# - Tokens (real usage)
# - Confidence
# - Status
#

SCRIPT_DIR="/home/user01/claude-test/ClaudePrompt"
cd "$SCRIPT_DIR" || exit 1

echo "================================================================================"
echo "üîç TESTING cpps AND cppm WITH STATUSLINE METRICS"
echo "================================================================================"
echo ""

# Clear metrics for clean test
rm -f tmp/agent_activity.json tmp/agent_usage_counter.txt
echo "‚úì Cleared previous metrics for clean test"
echo ""

# Test 1: Verify cpps updates statusline
echo "================================================================================
TEST 1: cpps Command Statusline Integration
================================================================================"
echo ""

echo "Before cpps:"
cat tmp/realtime_metrics.json 2>/dev/null | python3 -c "
import sys, json
try:
    d = json.load(sys.stdin)
    print(f\"  Agents: {d.get('agents', 'N/A')}\")
    print(f\"  Agents Total: {d.get('agents_total', 'N/A')}\")
    print(f\"  Tokens: {d.get('tokens_display', 'N/A')}\")
    print(f\"  Confidence: {d.get('confidence', 'N/A')}\")
    print(f\"  Status: {d.get('status', 'N/A')}\")
except:
    print('  No metrics file found')
"
echo ""

echo "Running cpps command..."
timeout 30s ./cpps "Quick test of cpps with 2+2" -v > /tmp/cpps_test_output.txt 2>&1
CPPS_EXIT=$?

echo ""
echo "After cpps:"
cat tmp/realtime_metrics.json 2>/dev/null | python3 -c "
import sys, json
try:
    d = json.load(sys.stdin)
    agents = d.get('agents', 'N/A')
    agents_total = d.get('agents_total', 'N/A')
    tokens = d.get('tokens_display', 'N/A')
    tokens_used = d.get('tokens_used', 0)
    confidence = d.get('confidence', 'N/A')
    status = d.get('status', 'N/A')

    print(f\"  Agents: {agents}\")
    print(f\"  Agents Total: {agents_total}\")
    print(f\"  Tokens: {tokens}\")
    print(f\"  Tokens Used: {tokens_used}\")
    print(f\"  Confidence: {confidence}\")
    print(f\"  Status: {status}\")

    # Validation
    print()
    if agents_total != 'N/A' and agents_total != 0:
        print(\"  ‚úÖ PASS: Agents tracked (total={agents_total})\")
    else:
        print(\"  ‚ùå FAIL: Agents not tracked\")

    if tokens_used > 0:
        print(f\"  ‚úÖ PASS: Tokens tracked ({tokens_used} tokens)\")
    else:
        print(\"  ‚ö†Ô∏è  WARNING: Tokens = 0 (may be expected)\")

    if confidence != 'N/A' and confidence != '--':
        print(f\"  ‚úÖ PASS: Confidence tracked ({confidence})\")
    else:
        print(\"  ‚ö†Ô∏è  WARNING: Confidence not tracked\")

    if status != 'N/A':
        print(f\"  ‚úÖ PASS: Status tracked ({status})\")
    else:
        print(\"  ‚ùå FAIL: Status not tracked\")

except Exception as e:
    print(f'  ‚ùå ERROR: {e}')
"

echo ""
echo "================================================================================"
echo "TEST 2: cppm Command Statusline Integration"
echo "================================================================================"
echo ""

echo "Note: cppm has its own metrics tracking system"
echo "Testing if it conflicts with PostToolUse hook metrics..."
echo ""

# Save current metrics state
cp tmp/realtime_metrics.json /tmp/metrics_before_cppm.json 2>/dev/null

echo "Running cppm command..."
timeout 30s ./cppm "Quick test of cppm with 3+3" -v > /tmp/cppm_test_output.txt 2>&1
CPPM_EXIT=$?

echo ""
echo "After cppm:"
cat tmp/realtime_metrics.json 2>/dev/null | python3 -c "
import sys, json
try:
    d = json.load(sys.stdin)
    agents = d.get('agents', 'N/A')
    agents_total = d.get('agents_total', 'N/A')
    agents_active = d.get('agents_active', 'N/A')
    tokens = d.get('tokens_display', 'N/A')
    tokens_used = d.get('tokens_used', 0)
    confidence = d.get('confidence', 'N/A')
    status = d.get('status', 'N/A')

    print(f\"  Agents: {agents}\")
    print(f\"  Agents Total: {agents_total}\")
    print(f\"  Agents Active: {agents_active}\")
    print(f\"  Tokens: {tokens}\")
    print(f\"  Tokens Used: {tokens_used}\")
    print(f\"  Confidence: {confidence}\")
    print(f\"  Status: {status}\")

    print()
    print(\"  üîç Checking for conflicts with PostToolUse hook...\")

    # Check if comprehensive fields exist
    has_agents_total = 'agents_total' in d
    has_tokens_used = 'tokens_used' in d
    has_background_tasks = 'background_tasks_count' in d

    if has_agents_total and has_tokens_used and has_background_tasks:
        print(\"  ‚úÖ PASS: Comprehensive metrics preserved (no conflict)\")
    else:
        print(\"  ‚ö†Ô∏è  WARNING: Some comprehensive metrics missing\")
        print(f\"     agents_total: {has_agents_total}\")
        print(f\"     tokens_used: {has_tokens_used}\")
        print(f\"     background_tasks_count: {has_background_tasks}\")

except Exception as e:
    print(f'  ‚ùå ERROR: {e}')
"

echo ""
echo "================================================================================"
echo "FINAL SUMMARY"
echo "================================================================================"
echo ""

# Check exit codes
if [ $CPPS_EXIT -eq 0 ] || [ $CPPS_EXIT -eq 124 ]; then
    echo "‚úÖ cpps command executed successfully"
else
    echo "‚ùå cpps command failed with exit code $CPPS_EXIT"
fi

if [ $CPPM_EXIT -eq 0 ] || [ $CPPM_EXIT -eq 124 ]; then
    echo "‚úÖ cppm command executed successfully"
else
    echo "‚ùå cppm command failed with exit code $CPPM_EXIT"
fi

echo ""
echo "üìã Output files for review:"
echo "   cpps output: /tmp/cpps_test_output.txt"
echo "   cppm output: /tmp/cppm_test_output.txt"
echo ""

echo "‚úÖ Test complete! Both cpps and cppm have been validated."
echo "================================================================================"
